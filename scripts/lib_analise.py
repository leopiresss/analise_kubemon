import pickle

nome_dataset_default = 'svm'
def get_info_modelo(nome_dataset = nome_dataset_default):
    if nome_dataset == 'svm':
        return {
            'nome_dataset': 'svm',
            'parametros': {
                'arq_dataset_csv': '../dataset/svm.csv',
                'arq_dataset_pkl': '../dataset/svm.pkl'
            }
        }

def get_dataset_analise(nome_data_set = nome_dataset_default,analise_ganho_de_informacao=False):    
    info_modelo = get_info_modelo(nome_data_set)
    with open(info_modelo['parametros']['arq_dataset_pkl'], 'rb') as f:
        datasets = pickle.load(f)
        if analise_ganho_de_informacao:
            if 'features_ganho_informacao' not in datasets or datasets['features_ganho_informacao'] is None:
                raise ValueError("O dataset nÃ£o contÃ©m 'features_ganho_informacao' ou ela Ã© None. Execute primeiro a anÃ¡lise de ganho de informaÃ§Ã£o no notebook correspondente.")
            
            # Aplicar seleÃ§Ã£o de features baseada no ganho de informaÃ§Ã£o
            datasets['X_train'] = datasets['X_train'][datasets['features_ganho_informacao']]
            datasets['X_test'] = datasets['X_test'][datasets['features_ganho_informacao']]
            datasets['X_val'] = datasets['X_val'][datasets['features_ganho_informacao']]
            datasets['y_train'] = datasets['y_train']   
            datasets['y_test'] = datasets['y_test']
            datasets['y_val'] = datasets['y_val']
            datasets['X_train_scaled'] = datasets['X_train_scaled']
            datasets['X_test_scaled'] = datasets['X_test_scaled']
            datasets['X_val_scaled'] = datasets['X_val_scaled']
            datasets['classes_mapping'] = datasets['classes_mapping']
            datasets['features_ganho_informacao'] = datasets['features_ganho_informacao']
    return datasets


def main():
    """
    FunÃ§Ã£o principal para demonstrar o uso da biblioteca lib_analise
    """
    print("ğŸ” Biblioteca de AnÃ¡lise KubeMon")
    print("=" * 50)
    
    try:
        # Obter informaÃ§Ãµes do modelo padrÃ£o
        info_modelo = get_info_modelo()
        print(f"ğŸ“Š Dataset: {info_modelo['nome_dataset']}")
        print(f"ğŸ“ Arquivo CSV: {info_modelo['parametros']['arq_dataset_csv']}")
        print(f"ğŸ“¦ Arquivo PKL: {info_modelo['parametros']['arq_dataset_pkl']}")
        
        # Carregar dataset bÃ¡sico
        print("\nğŸ”„ Carregando dataset bÃ¡sico...")
        datasets_basico = get_dataset_analise(analise_ganho_de_informacao=False)
        
        print(f"âœ… Dataset bÃ¡sico carregado:")
        print(f"   â€¢ X_train shape: {datasets_basico['X_train'].shape}")
        print(f"   â€¢ X_test shape: {datasets_basico['X_test'].shape}")
        print(f"   â€¢ X_val shape: {datasets_basico['X_val'].shape}")
        print(f"   â€¢ Classes: {list(datasets_basico['classes_mapping'].keys())}")
        
        # Tentar carregar dataset com anÃ¡lise de ganho de informaÃ§Ã£o
        print("\nğŸ§  Tentando carregar dataset com anÃ¡lise de ganho de informaÃ§Ã£o...")
        try:
            datasets_gi = get_dataset_analise(analise_ganho_de_informacao=True)
            print(f"âœ… Dataset com ganho de informaÃ§Ã£o carregado:")
            print(f"   â€¢ Features selecionadas: {len(datasets_gi['features_ganho_informacao'])}")
            print(f"   â€¢ X_train shape reduzido: {datasets_gi['X_train'].shape}")
        except ValueError as e:
            print(f"âš ï¸ {e}")
        
    except Exception as e:
        print(f"âŒ Erro: {e}")
        print("   Verifique se os arquivos de dataset estÃ£o disponÃ­veis.")
    
    print("\nğŸ¯ Biblioteca pronta para uso!")


if __name__ == "__main__":
    main()
